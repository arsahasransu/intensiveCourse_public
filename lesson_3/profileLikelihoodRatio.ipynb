{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Profile likelihood ratio calculator\n",
    "\n",
    "Copyright (c) 2020, Pietro Vischia pietro.vischia@cern.ch\n",
    "\n",
    "\n",
    "### Implementation of a class for profile likelihood calculations, with and without systematic uncertainties\n",
    "Based on MINOS via iMinuit (Fred James' still rules)\n",
    "\n",
    "Maybe in the future port to tensorflow?\n",
    "\n",
    "##### Features\n",
    "- [x] Profiling\n",
    "- [x] Constraints on nuisance parameters\n",
    "- [ ] Pulls and impacts\n",
    "- [ ] Breakdown of systematic uncertainties\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.5.4\n"
     ]
    }
   ],
   "source": [
    "# Check profile likelihood\n",
    "import numpy as np\n",
    "import scipy as sp\n",
    "import scipy.stats as st\n",
    "from scipy import optimize as op\n",
    "import matplotlib\n",
    "%matplotlib inline\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "import sys\n",
    "\n",
    "import random\n",
    "import inspect\n",
    "from iminuit import Minuit\n",
    "import iminuit\n",
    "print(iminuit.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's see a simple class that calculates a profile likelihood ratio given a minus-log-likelidood.\n",
    "\n",
    "It supports freezing parameters to prefit values, and setting up Gaussian constraints for nuisance parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "class profile_likelihood_ratio():\n",
    "    def __init__(self, model, data, ts, minuslogmodel=None, freezelist=None,nsteps=100, migradprecision=None):\n",
    "        self.model = model\n",
    "        self.minuslogmodel = minuslogmodel\n",
    "        self.n_params=len(self.model.__code__.co_varnames)-2\n",
    "        self.data = data\n",
    "        self.ts=ts\n",
    "        self.migradprecision= migradprecision\n",
    "        self.constraints = {}\n",
    "        self.initial_values=[1. for i in range(self.n_params)]\n",
    "        #self.likelihood_realization=lambda params : -2*(self.model(self.ts(self.data), params))\n",
    "        self.likelihood_realization=lambda params : (self.model(self.data, params)) # I save it but I DO NOT USE IT\n",
    "        self.minusloglikelihood_realization= lambda params: 2*self.minuslogmodel(self.data, params) #if self.minuslogmodel else -2*np.log(self.model(self.data, params))\n",
    "        # Work with variable names, to exploit <function>.__code__.co_varnames to have arbitrary number of variables\n",
    "        self.pardict = { parname : 1 for parname in self.minuslogmodel.__code__.co_varnames if parname!='data' and parname!='params'} if self.minuslogmodel else { parname : 1 for parname in self.model.__code__.co_varnames if parname!='data' and parname!='params'}\n",
    "        self.freezelist= freezelist if freezelist else { parname : [False, None, False] for parname in self.pardict.keys()}\n",
    "        self.initial_values = [ 1. for i in range(self.n_params)]\n",
    "        self.mles = None\n",
    "        self.mleuncs = None\n",
    "        self.nsteps = nsteps # For plotting\n",
    "    def __call__(self, params):\n",
    "        # I need the class to be callable, in order to call it. Sweet.\n",
    "        return self.minusloglikelihood_realization(params)\n",
    "        \n",
    "    def minimize(self):\n",
    "        # scipy.optimize.minimize is so crappy that I switched to iMinuit, and am happy\n",
    "        #ret = op.minimize(self, self.initial_values, constraints=self.constraints )\n",
    "\n",
    "        # Errordef should be 0.5 for -lnL, and 1 for least_squares, according to iminuit tutorial\n",
    "        # However, I am already multiplying -lnL by 2, so the correct errordef value is 1.\n",
    "\n",
    "        # Instance the minimizer\n",
    "        m = Minuit.from_array_func(plr, self.initial_values, name=self.pardict.keys(), errordef=1) \n",
    "        m.print_level=3 # 0: silent. 3: even low-level Minuit messages\n",
    "        \n",
    "        # Take care of frozen parameters and constrain nuisance parameters\n",
    "        for par, freezestatus in self.freezelist.items():\n",
    "            print('par %s has freezestatus %s'%(par, freezestatus))\n",
    "          \n",
    "            if freezestatus[1] is not None: # Set the input value of parameters that need to be frozen to their input value\n",
    "                m.fitarg[par] = freezestatus[1]\n",
    "                m.values[par] = freezestatus[1]\n",
    "                m.fitarg['error_%s'%par] = 0.\n",
    "                print('I am freezing (conditioning on) parameter %s to %s'%(par, freezestatus[1]))\n",
    "            if freezestatus[2]: # Nuisance parameters that need to be constrained\n",
    "                m.fitarg[par] = ...### FILL THIS\n",
    "                m.values[par] = ....### FILL THIS\n",
    "                m.fitarg['error_%s'%par] = ...### FILL THIS\n",
    "                print('I am settting the initial value of... ')\n",
    "            \n",
    "            # Freeze all parameters that need to be frozen\n",
    "            m.fitarg['fix_%s'%par] = freezestatus[0] # Freeze it\n",
    "            m.fixed[par] = freezestatus[0]\n",
    "            print('Minuit model settings:', m.fitarg)\n",
    "            \n",
    "        print('Minimizer will run with the following model settings: ', m.fitarg)\n",
    "        \n",
    "        # Minimize\n",
    "        if self.migradprecision:\n",
    "            m.migrad(precision=self.migradprecision)\n",
    "        else:\n",
    "            m.migrad()\n",
    "        \n",
    "        m.hesse()\n",
    "        \n",
    "        # Covariance matrix\n",
    "        print(m.covariance)\n",
    "        # Correlation matrix\n",
    "        # m.covariance.correlation()  # Minuit has changed interface inbetween versions?\n",
    "        \n",
    "        m.minos(sigma=1) # Compute asymmetric uncertainties (better than m.hesse() ). Fred James rulezzz\n",
    "        print('I have run MINOS')\n",
    "        print(m.params)\n",
    "        \n",
    "        # Minos profile\n",
    "        m.draw_mnprofile(list(self.pardict.keys())[0],subtract_min=True) # Draw MINOS intervals                                                                                                                                                                                                                 \n",
    "        #m.draw_profile(list(self.pardict.keys())[0],subtract_min=True); # Draws Hesse intervals\n",
    "                                 \n",
    "        \n",
    "        return [m.values, m.merrors] # when calling m.minos()\n",
    "        #return [m.values, m.errors] # when calling only m.hesse()\n",
    "        \n",
    "    def do_global_fit(self):\n",
    "        \n",
    "        # Main fit\n",
    "        results=self.minimize()\n",
    "        \n",
    "        # Look at results\n",
    "        print('Main fit Results', results)\n",
    "        print('Main fit Best estimates', results[0])\n",
    "        print('Main fit Uncertainties', results[1])\n",
    "        self.mles = { par : results[0][par] for par in self.pardict.keys() }\n",
    "        self.mleuncs = {}\n",
    "        for par in self.pardict.keys():\n",
    "            if self.freezelist[par][0] == False:\n",
    "                self.mleuncs[par, +1] = results[1][par, +1.0]\n",
    "                self.mleuncs[par, -1] = results[1][par, -1.0]\n",
    "\n",
    "        for par, val in self.mles.items():\n",
    "            if self.freezelist[par][0] == False:\n",
    "                print('Parameter %s = %s (+%s/-%s) [fitted]'%(par,val, self.mleuncs[par, +1],self.mleuncs[par, -1]))\n",
    "            else:\n",
    "                print('Parameter %s = %s [frozen]'%(par,val))\n",
    "    \n",
    "    def compute_model_at(self, datapoint, pars):\n",
    "        print(self.model(datapoint, pars))\n",
    "        \n",
    "    def plot_results(self, scan):\n",
    "        pass\n",
    "        \n",
    "    def find_range_around_mle(self, par):\n",
    "        mle = self.mles[par]\n",
    "        # Wild guess, must find a more meaningful way (maybe pre-finding the range in which it's nonzero)\n",
    "        return [mle+5*self.mleuncs[par, -1], mle+5*self.mleuncs[par, +1]] if self.freezelist[par][0] == False else [mle-5*abs(mle), mle+5*abs(mle)]\n",
    "    \n",
    "    def draw_data(self):\n",
    "        fig = plt.figure(figsize=(10,10))\n",
    "        plt.hist(self.data, bins=100)\n",
    "        thepar=list(self.pardict.keys())[0] # Assume the location parameter is kind of the first parameter\n",
    "        plt.axvline(x=self.ts(self.data), ls='--', c='red', label='Test statistic value')\n",
    "        plt.axvline(x=self.mles[thepar], ls='--', c='black', label='Maximum likelihood estimate for location parameter theta')\n",
    "        plt.axvspan(self.mles[thepar]+self.mleuncs[thepar, -1],self.mles[thepar]+self.mleuncs[thepar,+1], alpha=0.5, color='grey', label='68.3% CL interval')\n",
    "\n",
    "        plt.legend(loc='best')\n",
    "        \n",
    "    def draw_likelihood(self, override_range=None):\n",
    "        ret=[]\n",
    "        # Draw the 1D likelihoods\n",
    "        # This doesn't work properly yet: it will be the nucleus of the systematic breakdown by freezing stuff\n",
    "        # but it still has undebugged issues\n",
    "        for par in self.pardict.keys():\n",
    "            print('NOW PLOTTING %s'%par)\n",
    "            par_idx = list(self.pardict.keys()).index(par)\n",
    "            fig = plt.figure(figsize=(10,10))\n",
    "            scanrange = self.find_range_around_mle(par)\n",
    "            if override_range: # I can't remember what is this\n",
    "                if override_range[par]:\n",
    "                    scanrange=override_range[par]\n",
    "\n",
    "            # Pick the MLES for floating parameters, and the input values for the frozen ones\n",
    "            theparams=[ [ j for j in self.initial_values] for i in range(self.nsteps) ]\n",
    "            conditionlist = { conditionedpar : None for conditionedpar in self.pardict.keys() if conditionedpar!= par  }\n",
    "            \n",
    "            for i_params in range(self.nsteps):\n",
    "                for mledpar in self.pardict.keys():\n",
    "                    if mledpar != par:\n",
    "                        mledpar_idx=list(self.pardict.keys()).index(mledpar)\n",
    "                        theparams[i_params][mledpar_idx] = self.mles[mledpar] \n",
    "                        if self.freezelist[mledpar][0]:\n",
    "                            theparams[i_params][mledpar_idx] = self.freezelist[mledpar][1]\n",
    "                        conditionlist[mledpar] = theparams[i_params][mledpar_idx]\n",
    "     \n",
    "            print('Plotting %s in range %s in %s steps'%(par, scanrange, self.nsteps))            \n",
    "            x=np.linspace(scanrange[0], scanrange[1], num=self.nsteps)\n",
    "            \n",
    "            for idx in range(self.nsteps):\n",
    "                #print(idx, x[idx], theparams[idx][par_idx])\n",
    "                theparams[idx][par_idx] = x[idx]\n",
    "                #print('\\t', idx, x[idx], theparams[idx][par_idx])\n",
    "\n",
    "\n",
    "            y= [self(params) for params in theparams ]\n",
    "            #print('Theparams', theparams)\n",
    "            #for my_idx in range(self.nsteps):\n",
    "            #    print(my_idx, theparams[my_idx], y[my_idx])\n",
    "            #print('linspace x', x)\n",
    "            plt.plot(x,y-np.nanmin(y), label='Delta ln(L) scan')\n",
    "            plt.axvline(x=self.mles[par], ls='--', c='red', label='Maximum likelihood estimate')\n",
    "            plt.axhline(y=1, c='blue', ls='--', alpha=0.5, label='68.3% CL')\n",
    "            plt.axhline(y=4, c='blue', ls='--', alpha=0.5, label='95% CL')\n",
    "            #1D: 1, 4; 2D: 2.29, 5.99)\n",
    "            if self.freezelist[par][0] == False:\n",
    "                plt.axvspan(self.mles[par]+self.mleuncs[par, -1],self.mles[par]+self.mleuncs[par,+1], alpha=0.5, color='grey', label='68.3% CL interval')\n",
    "            plt.xlabel('Scan of %s while fixing %s'%(par, [[key, value] for key, value in conditionlist.items()]))\n",
    "            plt.ylabel('Delta ln(L)')\n",
    "            plt.ylim(-1,10)\n",
    "            plt.legend(loc='best')\n",
    "            ret.append(fig)\n",
    "        return ret\n",
    "        \n",
    "    def print_inputs(self, alsoData=False):\n",
    "        if(alsoData):\n",
    "            print('Data:')\n",
    "            print(data)\n",
    "        print('Test statistic: ')\n",
    "        print(self.ts)\n",
    "        print('Test statistic value:')\n",
    "        print(self.ts(self.data))\n",
    "        print('Parameters:')\n",
    "        print(self.model.__code__.co_varnames)\n",
    "        print('Parameters dictionary:')\n",
    "        print(self.pardict)\n",
    "        print('Initial values:')\n",
    "        print(self.initial_values)\n",
    "        print('Model:')\n",
    "        print(inspect.getsource(self.model))\n",
    "        print('[UNUSED] Likelihood model (fixed data):')\n",
    "        print(inspect.getsource(self.likelihood_realization))\n",
    "        print('[UNUSED] Likelihood model parameters:')\n",
    "        print(self.likelihood_realization.__code__.co_varnames)\n",
    "        print('minus-log-Likelihood model (fixed data):')\n",
    "        print(inspect.getsource(self.minusloglikelihood_realization))\n",
    "        print('minus-log-Likelihood model parameters:')\n",
    "        print(self.minusloglikelihood_realization.__code__.co_varnames)\n",
    "        #print(self.model)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's start with a Gaussian likelihood, of which we attempt to estimate both the mean and the variance.\n",
    "\n",
    "The datasets is sampled from a Gaussian with $\\theta_{true}=5$ and $\\sigma_{\\true}=2$.\n",
    "\n",
    "You need to write down the minus-log-likelihood function. Look at the profiled regions.\n",
    "\n",
    "You can play with the number of data and with the true values used to generate the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# First let's start with a gaussian likelihood\n",
    "def my_gaussian_likelihood(data, params):\n",
    "    pass\n",
    "\n",
    "def my_gaussian_minusloglikelihood(data, params):\n",
    "    theta=params[0]\n",
    "    sigma=params[1]\n",
    "    return # THE VALUE OF THE MINUS LOG LIKELIHOOD\n",
    "\n",
    "\n",
    "Ntot=10000\n",
    "data = np.array([ random.gauss(5,2) for i in range(Ntot)])\n",
    "debug=True\n",
    "\n",
    "plr = profile_likelihood_ratio(my_gaussian_likelihood, data, np.mean, my_gaussian_minusloglikelihood)\n",
    "\n",
    "if debug:\n",
    "    plr.print_inputs()\n",
    "plr.do_global_fit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Visualize the data, the true value, and the sampling mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "figs = plr.draw_data()\n",
    "\n",
    "plt.show()\n",
    "\n",
    "\n",
    "# figs = plr.draw_likelihood({'theta' : None, 'sigma' : None}) # this doesn't work properly yet\n",
    "#for fig in figs:\n",
    "#    plt.show()\n",
    "\n",
    "#x = np.linspace(0,10)\n",
    "#y = [ my_gaussian_likelihood(data[0], [x_i, 1]) for x_i in x]\n",
    "#plt.plot(x, y)\n",
    "#plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now you have to write a Poisson model for the case of a signal and one background.\n",
    "\n",
    "I remind you that you need to parameterize the signal yield in terms of signal strength $\\mu = \\frac{\\sigma}{\\sigma_{expected}}$\n",
    "\n",
    "The model is:\n",
    "    \n",
    "$$\n",
    "p(X|\\mu,s,b)= Pois(X | \\mu s + b)\n",
    "$$\n",
    "\n",
    "And that to write down the likelihood you need to condition on the observed data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def my_poisson_count_model_1bin_nonuisance(data, params):\n",
    "    pass\n",
    "\n",
    "def my_poisson_count_model_1bin_nonuisance_minusloglikelihood(data, params): # analytical loglikelihood better computationally (small values)\n",
    "    mu=params[0] # POI\n",
    "    s=params[1] \n",
    "    b=params[2]\n",
    "    \n",
    "    return ### FILL HERE THE VALUE OF THE MINUS LOG LIKELIHOOD\n",
    "\n",
    "\n",
    "\n",
    "Nobs=20\n",
    "sexp=5\n",
    "bexp=15\n",
    "\n",
    "#print(inspect.getsource(my_marked_poisson_model_1bin_nonuisance))\n",
    "\n",
    "x=np.linspace(0,4, num=200) # scan mu\n",
    "y = [ my_poisson_count_model_1bin_nonuisance( Nobs, [x_i, sexp, bexp] ) for x_i in x  ]\n",
    "\n",
    "plt.plot(x,y, label='L( %s | mu*%s +%s)' %(Nobs, sexp, bexp))\n",
    "plt.xlabel('mu = s/s_exp')\n",
    "plt.ylabel('L(%s | mu*%s + %s)'%(Nobs, sexp, bexp))\n",
    "plt.legend(loc='best')\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's look at the likelihood for different values of the expected signal $s$ and background  $b$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "fig = plt.figure()\n",
    "ax = fig.gca(projection='3d')\n",
    "\n",
    "yy = np.linspace(1,10, num=10) # scan sexp\n",
    "xx = np.linspace(0,4, num=10) # scan mu\n",
    "zz = np.zeros( (xx.size, yy.size) )\n",
    "counter_y = 0\n",
    "for X in xx:\n",
    "    counter_x = 0\n",
    "    for Y in xx:\n",
    "        zz[counter_x,counter_y] = my_poisson_count_model_1bin_nonuisance(Nobs, [X, Y, bexp])\n",
    "        counter_x += 1\n",
    "    counter_y += 1\n",
    "#zz=[ [ my_marked_poisson_model_1bin_nonuisance(Nobs, [X, Y, bexp]) for Y in yy ] for X in xx]\n",
    "print(len(xx), len(yy), len(zz))\n",
    "X, Y = np.meshgrid(xx,yy)\n",
    "#zz = my_marked_poisson_model_1bin_nonuisance( Nobs, [X, Y, bexp] ) \n",
    "#mmpm1n = np.vectorize(my_marked_poisson_model_1bin_nonuisance)\n",
    "#zz= mmpm1n( Nobs, [X, Y, bexp])\n",
    "#print(my_marked_poisson_model_1bin_nonuisance( Nobs, [0.88888889, 3, bexp] ) )\n",
    "#zz = [ my_marked_poisson_model_1bin_nonuisance( Nobs, [xx_i, yy_i, bexp] ) for xx_i, yy_i in zip(X, Y) ]\n",
    "ax.plot_wireframe(X, Y, zz )\n",
    "ax.set_xlabel('mu = s/s_exp')\n",
    "ax.set_ylabel('Expected signal sexp')\n",
    "#ax.set_zlim(0, 0.0000001)\n",
    "#Nobs=45\n",
    "#debug=True\n",
    "\n",
    "#plr = profile_likelihood_ratio(my_gaussian_likelihood, data, np.mean, my_gaussian_minusloglikelihood)\n",
    "\n",
    "#if debug:\n",
    "#    plr.print_inputs()\n",
    "#plr.do_global_fit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run the likelihood fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now try   profile likelihood ratio routine with this simple model\n",
    "Ntot=1000\n",
    "data = st.poisson.rvs(20, size=Ntot)\n",
    "data = 20\n",
    "debug=True\n",
    "\n",
    "\n",
    "# 'mu': [ mustBeFrozen, value to freeze to, isNuisanceParameter],\n",
    "freezelist = {'mu': [ FILL HERE],\n",
    "              's': [ FILL HERE ],\n",
    "              'b': [FILL  HERE ]}\n",
    "\n",
    "plr = profile_likelihood_ratio(my_poisson_count_model_1bin_nonuisance, data, np.mean, my_poisson_count_model_1bin_nonuisance_minusloglikelihood, freezelist)\n",
    "\n",
    "if debug:\n",
    "    plr.print_inputs()\n",
    "plr.do_global_fit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we want to add a nuisance parameter and model it as a Gaussian distribution.\n",
    "\n",
    "We encode a nuisance parameter $\\alpha$ acting on the background yield (uncertainty in the background normalization) as \n",
    "\n",
    "$$\n",
    "\\mathcal{L}(\\mathbf{n}, \\mathbf{\\alpha^0} | \\mu, \\mathbf{\\alpha}) = \\prod_{i\\in bins} \\mathcal{P}(n_i | \\mu S_i(\\mathbf{\\alpha}) \\\n",
    "+ B_i(\\mathbf{\\alpha}))\\times \\prod_{j\\in syst} \\mathcal{G}(\\alpha_j^0 | \\alpha_j, \\delta\\alpha_j)$\\\\\n",
    "$$\n",
    "\n",
    "And end up rescaling it such that the Gaussian is centered at 0 and with unit variance\n",
    "\n",
    "$$\n",
    "\\mathcal{L}(\\mathbf{n}, 0 | \\mu, \\mathbf{\\alpha}) = \\prod_{i\\in bins} \\mathcal{P}(n_i | \\mu S_i(\\mathbf{\\alpha}) + B_i(\\mathbf{\\alpha}))\\times \\prod_{j\\in syst} \\mathcal{G}(0 | \\alpha_j, 1)\n",
    "$$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now let's try to add a nuisance parameter.\n",
    "\n",
    "# First let's have one bin (channel) and check it works\n",
    "def my_poisson_count_model_1bin(data, params):\n",
    "    pass\n",
    "\n",
    "\n",
    "def my_poisson_count_model_1bin_minusloglikelihood(data, params): # analytical loglikelihood better computationally (small values)\n",
    "    mu=params[0] # POI\n",
    "    s=params[1] # We will condition on this\n",
    "    b=params[2] # We will condition on this\n",
    "    bunc=params[3] # We will profile this\n",
    "\n",
    "    return ### FILL HERE THE VALUE OF THE MINUS LOG LIKELIHOOD\n",
    "\n",
    "\n",
    "Nobs=20\n",
    "sexp=5\n",
    "bexp=15\n",
    "bunc=0.2\n",
    "x=np.linspace(0,4, num=200) # scan mu\n",
    "\n",
    "\n",
    "y = [ my_poisson_count_model_1bin_minusloglikelihood( Nobs, [x_i, sexp, bexp, bunc] ) for x_i in x  ]\n",
    "#y = my_poisson_count_model_1bin(Nobs, [x, sexp, bexp, bunc])\n",
    "plt.plot(x,y, label='Pois( %s | mu*%s + %s(1+%s*%s))*Gaus(0|%s,1)' %(Nobs, sexp, bexp, bunc, bexp, bunc))\n",
    "plt.xlabel('mu = s/s_exp')\n",
    "plt.ylabel('L(%s | mu*%s + %s(1+%s*%s))*Gaus(0|%s,1)'%(Nobs, sexp, bexp, bunc, bexp,bunc))\n",
    "#plt.ylim(0,0.12)\n",
    "plt.legend(loc='best')\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now profile it!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Ntot=1000\n",
    "#data = st.poisson.rvs(20, size=Ntot)\n",
    "\n",
    "debug=True\n",
    "\n",
    "data = 50\n",
    "sexp=5\n",
    "bexp=15\n",
    "bunc=0.0002\n",
    "\n",
    "freezelist = {'mu': [ FILL HERE ],\n",
    "              's': [ FILL HERE],\n",
    "              'b': [FILL HERE],\n",
    "              'bunc': [FILL HERE]}\n",
    "\n",
    "plr = profile_likelihood_ratio(my_poisson_count_model_1bin, data, np.mean, minuslogmodel=my_poisson_count_model_1bin_minusloglikelihood, freezelist=freezelist,migradprecision=0.0001)\n",
    "#migradprecision=0.1\n",
    "if debug:\n",
    "    plr.print_inputs()\n",
    "plr.do_global_fit()\n",
    "plr.draw_likelihood()\n",
    "plr.draw_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
